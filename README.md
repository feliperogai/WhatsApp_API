# ğŸ¤– Jarvis WhatsApp LLM Agent Orchestrator v2.0

Sistema revolucionÃ¡rio de orquestraÃ§Ã£o de agentes IA para WhatsApp usando **LangChain**, **LangGraph** e **LLM** (Ollama/OpenAI), transformando conversas simples em experiÃªncias inteligentes e contextuais.

## ğŸš€ Novidades v2.0 - IA RevolucionÃ¡ria

### âœ¨ **Processamento de Linguagem Natural AvanÃ§ado**
- **LLM Integrado**: Ollama (local) + OpenAI (fallback)
- **CompreensÃ£o Contextual**: Entende nuances e subtextos
- **Respostas Humanas**: Conversas naturais e inteligentes

### ğŸ§  **OrquestraÃ§Ã£o Inteligente com LangGraph**
- **Fluxo DinÃ¢mico**: Roteamento baseado em IA
- **ClassificaÃ§Ã£o AutomÃ¡tica**: IntenÃ§Ãµes detectadas automaticamente
- **Contexto Persistente**: MemÃ³ria conversacional avanÃ§ada

### ğŸ¯ **4 Agentes IA Especializados**
1. **ğŸ¢ Reception Agent IA**: Triagem inteligente com LLM
2. **ğŸ§  Classification Agent IA**: ClassificaÃ§Ã£o avanÃ§ada de intenÃ§Ãµes
3. **ğŸ“Š Data Agent IA**: AnÃ¡lise inteligente de dados e insights
4. **ğŸ”§ Support Agent IA**: DiagnÃ³stico tÃ©cnico automatizado

## âš™ï¸ ConfiguraÃ§Ã£o RÃ¡pida com IA

### 1. **PrÃ©-requisitos**

```bash
# Docker & Docker Compose
curl -fsSL https://get.docker.com | sh

# Ollama (Servidor LLM Local)
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve
ollama pull llama3.1:8b
```

### 2. **Setup Automatizado IA**

```bash
git clone 
cd whatsapp_agent_orchestrator
chmod +x setup_llm.sh
./setup_llm.sh
```

O script automaticamente:
- âœ… Detecta Ollama/OpenAI
- âœ… Configura variÃ¡veis LLM
- âœ… Testa conectividade IA
- âœ… Inicia sistema completo

### 3. **ConfiguraÃ§Ã£o Manual (Alternativa)**

```bash
# Clone e configure
cp .env.example .env

# Configure no .env:
OLLAMA_BASE_URL=http://192.168.15.31:11435
OLLAMA_MODEL=llama3.1:8b
OPENAI_API_KEY=your_key_here  # Opcional (fallback)

# Inicie
docker-compose up -d
```

## ğŸ§ª Teste a InteligÃªncia

### **Teste Automatizado Completo**
```bash
chmod +x test_llm.sh
./test_llm.sh +5511999999999  # Seu nÃºmero WhatsApp
```

### **Teste Manual dos Endpoints IA**
```bash
# Status da IA
curl http://localhost:8000/llm/status

# Teste direto do LLM
curl -X POST http://localhost:8000/llm/test \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Analise: preciso de relatÃ³rio de vendas"}'

# AnÃ¡lise de conversa
curl http://localhost:8000/analyze/+5511999999999

# SugestÃµes inteligentes
curl http://localhost:8000/suggestions/+5511999999999?context=suporte
```

## ğŸ’¬ Conversas Inteligentes - Exemplos

### **ğŸ“Š Consulta de Dados AvanÃ§ada**
```
ğŸ‘¤ "Preciso de uma anÃ¡lise detalhada das vendas, incluindo 
    comparativo com mÃªs anterior e projeÃ§Ãµes"

ğŸ¤– "ğŸ“Š **ANÃLISE COMPLETA DE VENDAS - NOVEMBRO/2024**

ğŸ’° Receita Atual: R$ 125.000,00
ğŸ“ˆ MÃªs Anterior: R$ 98.000,00  
ğŸ“Š Crescimento: +27.6% ğŸŸ¢

ğŸ‘¥ Clientes Ativos: 1.247 (+89)
ğŸ¯ Taxa ConversÃ£o: 3.2% (+0.4%)
ğŸ“ˆ **ProjeÃ§Ã£o Dezembro**: R$ 145.000 (baseado em tendÃªncia)

âœ¨ Status: ğŸŸ¢ **Excelente performance!**
ğŸ¯ **RecomendaÃ§Ã£o**: Manter estratÃ©gia atual e investir em marketing"
```

### **ğŸ”§ Suporte TÃ©cnico Inteligente**
```
ğŸ‘¤ "Sistema travando no login, erro 500"

ğŸ¤– "ğŸ”§ **DIAGNÃ“STICO AUTOMÃTICO INICIADO**

ğŸ” **AnÃ¡lise do Problema:**
- Erro 500: Problema servidor/banco de dados
- Login: ProvÃ¡vel sobrecarga de autenticaÃ§Ã£o

âš¡ **SOLUÃ‡Ã•ES IMEDIATAS:**
1ï¸âƒ£ Limpe cache e cookies
2ï¸âƒ£ Tente modo anÃ´nimo
3ï¸âƒ£ Aguarde 5 minutos (auto-recovery ativo)

ğŸ« **Ticket Criado:** TK47291
ğŸš¨ **Escalado para:** Equipe L2 (SLA: 30min)

ğŸ’¬ Vou acompanhar a resoluÃ§Ã£o. Te atualizo em 15min!"
```

## ğŸ› ï¸ Arquitetura IA AvanÃ§ada

### **LangGraph Workflow**
```mermaid
graph TD
    A[Mensagem WhatsApp] --> B[Intent Router IA]
    B --> C{ClassificaÃ§Ã£o LLM}
    C -->|Dados| D[Data Agent IA]
    C -->|Suporte| E[Support Agent IA]
    C -->|Triagem| F[Reception Agent IA]
    C -->|AnÃ¡lise| G[Classification Agent IA]
    D --> H[Response Formatter]
    E --> H
    F --> H
    G --> H
    H --> I[Resposta Inteligente]
```

### **Stack TecnolÃ³gico**
- **ğŸ§  LLM**: Ollama (Llama 3.1) + OpenAI (fallback)
- **ğŸ”„ OrquestraÃ§Ã£o**: LangGraph + LangChain
- **ğŸ“± WhatsApp**: Twilio API
- **ğŸ’¾ SessÃµes**: Redis com contexto IA
- **ğŸš€ API**: FastAPI assÃ­ncrono
- **ğŸ³ Deploy**: Docker + Docker Compose

## ğŸ“¡ Endpoints IA DisponÃ­veis

### **BÃ¡sicos**
- `GET /` - Dashboard visual com status IA
- `POST /webhook/whatsapp` - Webhook Twilio (IA-powered)
- `GET /health` - Health check com status IA
- `GET /status` - Status detalhado (LLM + LangGraph)

### **LLM & IA (Novos)**
- `GET /llm/status` - Status especÃ­fico do LLM
- `POST /llm/test` - Teste direto do LLM
- `GET /analyze/{phone}` - AnÃ¡lise IA da conversa
- `GET /suggestions/{phone}` - SugestÃµes inteligentes

### **Gerenciamento**
- `POST /send` - Envio manual de mensagens
- `POST /reset-session` - Reset de sessÃ£o (+ memÃ³ria IA)
- `POST /broadcast` - Broadcast inteligente

## ğŸ›ï¸ ConfiguraÃ§Ãµes IA AvanÃ§adas

### **Modelos LLM Suportados**
```bash
# Recomendados para produÃ§Ã£o
llama3.1:8b      # Equilibrado (padrÃ£o)
qwen2.5:7b       # RÃ¡pido e eficiente
mistral:7b       # Bom para anÃ¡lise

# Para anÃ¡lises complexas
llama3.1:70b     # Muito potente (requer recursos)
codellama:7b     # Especializado em cÃ³digo
```

### **Tuning de Performance**
```bash
# .env - ConfiguraÃ§Ãµes otimizadas
LLM_TEMPERATURE=0.7      # Criatividade vs PrecisÃ£o
LLM_MAX_TOKENS=500       # Tamanho das respostas
AGENT_MEMORY_SIZE=10     # HistÃ³rico mantido
CONTEXT_WINDOW=4000      # Contexto por conversa
```

### **PersonalizaÃ§Ã£o dos Agentes**
```python
# Exemplo: Agente customizado
class CustomAgent(LLMBaseAgent):
    def _get_system_prompt(self) -> str:
        return """VocÃª Ã© um especialista em [SUA_ÃREA].
        [SUAS_INSTRUÃ‡Ã•ES_ESPECÃFICAS]"""
    
    def _is_intent_compatible(self, intent: str) -> bool:
        return intent == "custom_intent"
```

## ğŸ“Š Monitoramento IA

### **Dashboard Inteligente**
```bash
# Acesse: http://localhost:8000
# Mostra: Status LLM, agentes ativos, mÃ©tricas de IA
```

### **Logs Estruturados**
```bash
# Em tempo real
docker-compose logs -f jarvis-whatsapp

# AnÃ¡lise especÃ­fica
docker-compose logs jarvis-whatsapp | grep "LLM"
```

### **MÃ©tricas de IA**
- Tempo de resposta LLM
- Taxa de sucesso na classificaÃ§Ã£o
- ConfianÃ§a mÃ©dia das respostas
- SessÃµes ativas com contexto
- Performance por agente

## ğŸš€ Deploy ProduÃ§Ã£o IA

### **Docker Swarm com IA**
```yaml
version: '3.8'
services:
  jarvis-llm:
    image: jarvis-whatsapp-llm:latest
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 2G      # Mais memÃ³ria para IA
          cpus: '2.0'     # Mais CPU para LLM
    environment:
      - OLLAMA_BASE_URL=http://ollama-cluster:11434
      - LLM_TEMPERATURE=0.5  # ProduÃ§Ã£o mais conservadora
```

### **Cluster Ollama**
```bash
# Setup cluster Ollama para alta disponibilidade
docker run -d --name ollama-node1 -p 11434:11434 ollama/ollama
docker run -d --name ollama-node2 -p 11435:11434 ollama/ollama
```

## ğŸ”’ SeguranÃ§a IA

- **ğŸ›¡ï¸ ValidaÃ§Ã£o LLM**: Entrada/saÃ­da sanitizada
- **ğŸ” Rate Limiting**: Por usuÃ¡rio e endpoint
- **ğŸ“ Logs Seguros**: Sem dados sensÃ­veis
- **ğŸš« Content Filter**: Filtragem automÃ¡tica de conteÃºdo

## ğŸ“ˆ Performance & Escalabilidade

### **Benchmarks**
- **LatÃªncia LLM**: 500-2000ms (dependendo do modelo)
- **Throughput**: 100+ conversas simultÃ¢neas
- **MemÃ³ria**: 1-4GB por instÃ¢ncia (+ modelo LLM)
- **CPU**: Otimizado para GPU (CUDA) quando disponÃ­vel

### **OtimizaÃ§Ãµes**
```bash
# Para mÃ¡xima performance
LLM_MODEL=qwen2.5:7b        # Modelo mais rÃ¡pido
LLM_TEMPERATURE=0.3         # Menos variabilidade
LLM_MAX_TOKENS=300          # Respostas mais concisas
AGENT_MEMORY_SIZE=5         # Menos contexto
```

## ğŸ¤ Contribuindo para a IA

### **Adicionando Novos Agentes IA**
1. Herde de `LLMBaseAgent`
2. Implemente `_get_system_prompt()`
3. Registre no `LangGraphOrchestrator`
4. Teste com `test_llm.sh`

### **Melhorando Prompts**
- Siga padrÃµes de prompt engineering
- Use few-shot learning quando necessÃ¡rio
- Teste com mÃºltiplos modelos
- Valide saÃ­da com testes automatizados

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob licenÃ§a MIT. Veja `LICENSE` para detalhes.

## ğŸ†˜ Suporte & Comunidade

- ğŸ“§ **Email**: suporte@jarvis-ia.com
- ğŸ’¬ **Discord**: [Comunidade Jarvis IA]
- ğŸ“– **Docs IA**: [docs.jarvis-ia.com]
- ğŸ› **Issues**: [GitHub Issues]

---

**ğŸ¤– Desenvolvido com â¤ï¸ e IA avanÃ§ada para revolucionar conversas no WhatsApp**

### ğŸ¯ **PrÃ³ximos Recursos (Roadmap)**
- ğŸ”Š **Voice-to-Text** com Whisper
- ğŸ–¼ï¸ **AnÃ¡lise de Imagem** com Vision Models  
- ğŸŒ **Multi-idioma** automÃ¡tico
- ğŸ“± **App Mobile** para gestÃ£o
- ğŸ”— **IntegraÃ§Ã£o CRM/ERP** nativa
- ğŸ§  **Fine-tuning** personalizado

**Jarvis v2.0 - Onde ConversaÃ§Ã£o encontra InteligÃªncia Artificial! ğŸš€ğŸ¤–**