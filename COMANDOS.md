# üöÄ Comandos R√°pidos - Jarvis LLM v2.0

**Sistema otimizado para seu Ollama em: http://192.168.15.31:11435**

## ‚ö° Setup R√°pido (3 comandos)

```bash
# 1. Otimizar projeto
chmod +x optimize_project.sh && ./optimize_project.sh

# 2. Setup autom√°tico
chmod +x setup_llm.sh && ./setup_llm.sh

# 3. Testar sistema
./test_llm.sh
```

## üéØ Comandos Principais

### Setup e Inicializa√ß√£o
```bash
./setup_llm.sh              # Setup otimizado para seu Ollama
docker-compose up -d         # Iniciar servi√ßos
docker-compose down          # Parar servi√ßos
docker-compose restart       # Reiniciar servi√ßos
```

### Testes
```bash
./test_llm.sh                        # Teste completo
./test_llm.sh +5511999999999         # Teste com envio para n√∫mero
curl http://localhost:8000/health    # Health check r√°pido
```

### Monitoramento
```bash
./monitor_llm.sh             # Monitor em tempo real
./monitor_llm.sh once        # Ver status uma vez
./monitor_llm.sh test        # Teste r√°pido de conectividade
docker-compose logs -f       # Logs em tempo real
```

## üß† Testes LLM Diretos

### Via API
```bash
# Teste b√°sico
curl -X POST http://localhost:8000/llm/test \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Ol√°, como voc√™ est√°?"}'

# Status LLM
curl http://localhost:8000/llm/status

# Status geral
curl http://localhost:8000/status
```

### Via Ollama Direto (seu comando)
```bash
curl -s http://192.168.15.31:11435/api/chat -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.1:8b",
    "messages": [
      { "role": "user", "content": "Qual √© a capital do Brasil..." }
    ]
  }' | jq -r '.message.content' | tr -d '\n'
```

## üì± WhatsApp

### Configura√ß√£o Webhook Twilio
```
URL: https://seu-ngrok-url.ngrok.io/webhook/whatsapp
Method: POST
```

### Mensagens de Teste
- "Ol√°" ‚Üí Ativa Reception Agent
- "Preciso de relat√≥rio de vendas" ‚Üí Data Agent
- "Sistema com erro" ‚Üí Support Agent
- "Agendar reuni√£o" ‚Üí Classification Agent

### API de Envio
```bash
curl -X POST http://localhost:8000/send \
  -H "Content-Type: application/json" \
  -d '{
    "phone_number": "+5511999999999",
    "message": "Teste do Jarvis LLM!"
  }'
```

## üê≥ Docker

### Comandos √öteis
```bash
# Ver containers
docker-compose ps

# Logs espec√≠ficos
docker-compose logs jarvis-whatsapp-llm
docker-compose logs redis

# Rebuild
docker-compose build --no-cache
docker-compose up -d --force-recreate

# Limpar tudo
docker-compose down -v
docker system prune -f
```

### Resolver Problemas
```bash
# Se der erro de permiss√£o
sudo chmod +x *.sh

# Se Ollama n√£o conectar
curl -s http://192.168.15.31:11435/api/tags

# Se container n√£o iniciar
docker-compose logs jarvis-whatsapp-llm

# Resetar tudo
docker-compose down -v
./setup_llm.sh
```

## üîß Configura√ß√µes

### Arquivo .env Principal
```bash
# Ollama (seu setup)
OLLAMA_BASE_URL=http://192.168.15.31:11435
OLLAMA_MODEL=llama3.1:8b

# Twilio
TWILIO_ACCOUNT_SID=seu_sid
TWILIO_AUTH_TOKEN=seu_token
TWILIO_PHONE_NUMBER=+14155238886

# Webhook
WEBHOOK_BASE_URL=https://sua-url.ngrok.io
```

### Ajustar Performance
```bash
# Para respostas mais r√°pidas
LLM_MAX_TOKENS=300
LLM_TEMPERATURE=0.3

# Para respostas mais criativas
LLM_MAX_TOKENS=800
LLM_TEMPERATURE=0.8
```

## üìä URLs Importantes

```
http://localhost:8000          # Dashboard principal
http://localhost:8000/health   # Health check
http://localhost:8000/status   # Status detalhado
http://localhost:8000/llm/status # Status LLM espec√≠fico
```

## üÜò Resolu√ß√£o de Problemas

### Problema: Ollama n√£o conecta
```bash
# Testar Ollama
curl http://192.168.15.31:11435/api/tags

# Se n√£o responder, verificar:
# 1. Ollama est√° rodando?
# 2. Firewall bloqueando?
# 3. IP/porta corretos?
```

### Problema: Container n√£o inicia
```bash
# Ver logs detalhados
docker-compose logs jarvis-whatsapp-llm

# Comum: erro de depend√™ncias
docker-compose build --no-cache
```

### Problema: LLM n√£o responde
```bash
# Testar direto
./test_llm.sh

# Verificar mem√≥ria/CPU
docker stats

# Reiniciar LLM service
docker-compose restart jarvis-whatsapp-llm
```

## ‚ö° Atalhos R√°pidos

```bash
# Status r√°pido
alias js='./monitor_llm.sh once'

# Teste r√°pido
alias jt='./test_llm.sh'

# Logs r√°pidos
alias jl='docker-compose logs -f jarvis-whatsapp-llm'

# Restart r√°pido
alias jr='docker-compose restart jarvis-whatsapp-llm'
```

---

**ü§ñ Jarvis LLM v2.0 - Otimizado para seu Ollama!**