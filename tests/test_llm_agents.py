import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch
from datetime import datetime

from app.services.llm_service import LLMService
from app.agents.llm_reception_agent import LLMReceptionAgent
from app.agents.llm_classification_agent import LLMClassificationAgent
from app.agents.llm_data_agent import LLMDataAgent
from app.agents.llm_support_agent import LLMSupportAgent
from app.core.langgraph_orchestrator import LangGraphOrchestrator
from app.core.session_manager import SessionManager
from app.models.message import WhatsAppMessage, MessageType, MessageStatus
from app.models.session import UserSession

@pytest.fixture
async def llm_service():
    """Fixture do servi√ßo LLM mockado"""
    service = LLMService()
    service.primary_llm = Mock()
    service.session = AsyncMock()
    return service

@pytest.fixture
async def session_manager():
    """Fixture do gerenciador de sess√£o mockado"""
    manager = SessionManager()
    manager.redis_client = None  # For√ßa uso de mem√≥ria
    await manager.initialize()
    return manager

@pytest.fixture
def sample_message():
    """Fixture de mensagem de exemplo"""
    return WhatsAppMessage(
        message_id="test123",
        from_number="+5511999999999",
        to_number="+14155238886",
        body="Ol√°, preciso de ajuda",
        message_type=MessageType.TEXT,
        status=MessageStatus.RECEIVED
    )

@pytest.fixture
def sample_session():
    """Fixture de sess√£o de exemplo"""
    return UserSession(
        session_id="session_test_123",
        phone_number="+5511999999999",
        current_agent=None,
        conversation_context={},
        message_history=[]
    )

class TestLLMService:
    """Testes para o servi√ßo LLM"""
    
    @pytest.mark.asyncio
    async def test_initialize(self, llm_service):
        """Testa inicializa√ß√£o do servi√ßo LLM"""
        with patch('aiohttp.ClientSession') as mock_session:
            await llm_service.initialize()
            assert llm_service.session is not None
    
    @pytest.mark.asyncio
    async def test_generate_response_ollama(self, llm_service):
        """Testa gera√ß√£o de resposta com Ollama"""
        # Mock da resposta do Ollama
        mock_response = {
            "message": {"content": "Ol√°! Como posso ajud√°-lo?"}
        }
        
        with patch.object(llm_service.session, 'post') as mock_post:
            mock_post.return_value.__aenter__.return_value.status = 200
            mock_post.return_value.__aenter__.return_value.json = AsyncMock(return_value=mock_response)
            
            response = await llm_service.generate_response(
                prompt="Ol√°",
                system_message="Voc√™ √© um assistente",
                session_id="test_session"
            )
            
            assert response == "Ol√°! Como posso ajud√°-lo?"
            mock_post.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_classify_intent(self, llm_service):
        """Testa classifica√ß√£o de inten√ß√£o"""
        mock_response = """{"intent": "data_query", "confidence": 0.85, "reasoning": "Usu√°rio quer relat√≥rio"}"""
        
        with patch.object(llm_service, 'generate_response', return_value=mock_response):
            result = await llm_service.classify_intent("Preciso de um relat√≥rio de vendas")
            
            assert result["intent"] == "data_query"
            assert result["confidence"] == 0.85

class TestLLMReceptionAgent:
    """Testes para o agente de recep√ß√£o LLM"""
    
    @pytest.mark.asyncio
    async def test_can_handle_first_message(self, llm_service, sample_message, sample_session):
        """Testa se pode lidar com primeira mensagem"""
        agent = LLMReceptionAgent(llm_service)
        
        # Primeira intera√ß√£o (sem hist√≥rico)
        can_handle = await agent.can_handle(sample_message, sample_session)
        assert can_handle is True
    
    @pytest.mark.asyncio
    async def test_can_handle_menu_command(self, llm_service, sample_session):
        """Testa se pode lidar com comando de menu"""
        agent = LLMReceptionAgent(llm_service)
        
        menu_message = WhatsAppMessage(
            message_id="test124",
            from_number="+5511999999999",
            to_number="+14155238886",
            body="menu",
            message_type=MessageType.TEXT,
            status=MessageStatus.RECEIVED
        )
        
        can_handle = await agent.can_handle(menu_message, sample_session)
        assert can_handle is True
    
    @pytest.mark.asyncio
    async def test_process_message(self, llm_service, sample_message, sample_session):
        """Testa processamento de mensagem"""
        agent = LLMReceptionAgent(llm_service)
        
        mock_llm_response = """üëã Ol√°! Bem-vindo ao Jarvis Assistant!

Sou seu assistente virtual e posso te ajudar com:
‚Ä¢ üìä Consultas e relat√≥rios
‚Ä¢ üîß Suporte t√©cnico
‚Ä¢ üìã Agendamentos e tarefas

Como posso te ajudar hoje?"""
        
        with patch.object(llm_service, 'generate_response', return_value=mock_llm_response):
            response = await agent.process_message(sample_message, sample_session)
            
            assert response.agent_id == "reception_agent"
            assert "Bem-vindo" in response.response_text
            assert response.confidence > 0

class TestLLMClassificationAgent:
    """Testes para o agente de classifica√ß√£o LLM"""
    
    @pytest.mark.asyncio
    async def test_classify_data_query(self, llm_service, sample_session):
        """Testa classifica√ß√£o de consulta de dados"""
        agent = LLMClassificationAgent(llm_service)
        
        data_message = WhatsAppMessage(
            message_id="test125",
            from_number="+5511999999999",
            to_number="+14155238886",
            body="Preciso do relat√≥rio de vendas do √∫ltimo m√™s",
            message_type=MessageType.TEXT,
            status=MessageStatus.RECEIVED
        )
        
        # Mock da classifica√ß√£o
        mock_classification = {
            "intent": "data_query",
            "confidence": 0.9,
            "reasoning": "Usu√°rio solicita relat√≥rio de vendas"
        }
        
        mock_response = "Identifiquei que voc√™ precisa de dados. Conectando com analista!"
        
        with patch.object(llm_service, 'classify_intent', return_value=mock_classification), \
             patch.object(llm_service, 'generate_response', return_value=mock_response):
            
            response = await agent.process_message(data_message, sample_session)
            
            assert response.agent_id == "classification_agent"
            assert response.next_agent == "data_agent"
            assert response.metadata["intent_analysis"]["intent"] == "data_query"

class TestLLMDataAgent:
    """Testes para o agente de dados LLM"""
    
    @pytest.mark.asyncio
    async def test_process_sales_query(self, llm_service, sample_session):
        """Testa processamento de consulta de vendas"""
        agent = LLMDataAgent(llm_service)
        
        sales_message = WhatsAppMessage(
            message_id="test126",
            from_number="+5511999999999",
            to_number="+14155238886",
            body="Como est√£o as vendas?",
            message_type=MessageType.TEXT,
            status=MessageStatus.RECEIVED
        )
        
        mock_response = """üìä **RELAT√ìRIO DE VENDAS - NOVEMBRO/2024**

üí∞ Receita Atual: R$ 125.000,00
üìà Crescimento: +27.6% üü¢
üë• Clientes Ativos: 1.247"""
        
        with patch.object(llm_service, 'generate_response', return_value=mock_response):
            response = await agent.process_message(sales_message, sample_session)
            
            assert response.agent_id == "data_agent"
            assert "RELAT√ìRIO DE VENDAS" in response.response_text
            assert response.metadata["query_type"] == "sales"

class TestLLMSupportAgent:
    """Testes para o agente de suporte LLM"""
    
    @pytest.mark.asyncio
    async def test_process_error_report(self, llm_service, sample_session):
        """Testa processamento de relat√≥rio de erro"""
        agent = LLMSupportAgent(llm_service)
        
        error_message = WhatsAppMessage(
            message_id="test127",
            from_number="+5511999999999",
            to_number="+14155238886",
            body="Sistema est√° com erro 500 no login",
            message_type=MessageType.TEXT,
            status=MessageStatus.RECEIVED
        )
        
        mock_response = """üîß **DIAGN√ìSTICO AUTOM√ÅTICO**

üîç Erro 500: Problema servidor
‚ö° **SOLU√á√ïES:**
1Ô∏è‚É£ Limpe cache
2Ô∏è‚É£ Tente modo an√¥nimo
üé´ Ticket criado: TK12345"""
        
        with patch.object(llm_service, 'generate_response', return_value=mock_response):
            response = await agent.process_message(error_message, sample_session)
            
            assert response.agent_id == "support_agent"
            assert "DIAGN√ìSTICO" in response.response_text
            assert response.metadata["issue_type"] == "error"
            assert response.metadata["priority"] == "normal"

class TestLangGraphOrchestrator:
    """Testes para o orquestrador LangGraph"""
    
    @pytest.mark.asyncio
    async def test_orchestrator_initialization(self, session_manager, llm_service):
        """Testa inicializa√ß√£o do orquestrador"""
        orchestrator = LangGraphOrchestrator(session_manager, llm_service)
        
        assert orchestrator.workflow is not None
        assert len(orchestrator.agents) == 4
        assert "reception_agent" in orchestrator.agents
        assert "classification_agent" in orchestrator.agents
        assert "data_agent" in orchestrator.agents
        assert "support_agent" in orchestrator.agents
    
    @pytest.mark.asyncio
    async def test_process_message_flow(self, session_manager, llm_service, sample_message):
        """Testa fluxo completo de processamento"""
        orchestrator = LangGraphOrchestrator(session_manager, llm_service)
        
        # Mock das respostas dos agentes
        mock_classification = {
            "intent": "reception",
            "confidence": 0.8,
            "reasoning": "Sauda√ß√£o inicial"
        }
        
        mock_agent_response = "Ol√°! Como posso ajud√°-lo?"
        
        with patch.object(llm_service, 'classify_intent', return_value=mock_classification), \
             patch.object(llm_service, 'generate_response', return_value=mock_agent_response):
            
            response = await orchestrator.process_message(sample_message)
            
            assert response.response_text is not None
            assert response.agent_id is not None
            assert response.confidence >= 0

class TestIntegration:
    """Testes de integra√ß√£o"""
    
    @pytest.mark.asyncio
    async def test_full_conversation_flow(self, session_manager, llm_service):
        """Testa fluxo completo de conversa"""
        orchestrator = LangGraphOrchestrator(session_manager, llm_service)
        
        # Sequ√™ncia de mensagens
        messages = [
            ("Ol√°", "reception"),
            ("Preciso de relat√≥rio de vendas", "data_query"),
            ("Sistema com erro", "technical_support"),
            ("Obrigado", "reception")
        ]
        
        phone_number = "+5511999999999"
        
        for i, (text, expected_intent) in enumerate(messages):
            message = WhatsAppMessage(
                message_id=f"test_flow_{i}",
                from_number=phone_number,
                to_number="+14155238886",
                body=text,
                message_type=MessageType.TEXT,
                status=MessageStatus.RECEIVED
            )
            
            # Mock das classifica√ß√µes e respostas
            mock_classification = {
                "intent": expected_intent,
                "confidence": 0.8,
                "reasoning": f"Classificado como {expected_intent}"
            }
            
            mock_response = f"Resposta para: {text}"
            
            with patch.object(llm_service, 'classify_intent', return_value=mock_classification), \
                 patch.object(llm_service, 'generate_response', return_value=mock_response):
                
                response = await orchestrator.process_message(message)
                
                assert response is not None
                assert response.response_text is not None
        
        # Verifica se sess√£o foi mantida
        session = await session_manager.get_session(phone_number)
        assert session is not None
        assert len(session.message_history) == len(messages) * 2  # User + Agent messages

if __name__ == "__main__":
    pytest.main([__file__, "-v"])